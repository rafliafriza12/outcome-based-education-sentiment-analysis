{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning IndobERT with Numeric Features\n",
    "\n",
    "This notebook implements a hybrid model that combines IndobERT with numeric features for classification tasks, including comprehensive evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset as TorchDataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import os\n",
    "import argparse\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load dataset\n",
    "def load_dataset(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    return df\n",
    "\n",
    "# 2. Preprocessed dataset\n",
    "def preprocess_data(df):\n",
    "    # Separate features and label\n",
    "    feature_cols = [col for col in df.columns if col.startswith('feature_')]\n",
    "    X = df[feature_cols]  # Only use feature columns\n",
    "    y = df['label']\n",
    "    print(X.info())\n",
    "    \n",
    "    # Encoding label\n",
    "    unique_labels = y.unique()\n",
    "    if len(unique_labels) == 1:  # If there's only one label\n",
    "        print(f\"Warning: Dataset only has one label: {unique_labels[0]}\")\n",
    "        if 'negatif' in unique_labels:\n",
    "            label_map = {'negatif': 0, 'positif': 1, 'netral': 2}\n",
    "        else:\n",
    "            label_map = {unique_labels[0]: 0, 'other': 1}\n",
    "    else:\n",
    "        label_map = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "    \n",
    "    y = y.map(label_map)\n",
    "    \n",
    "    # Standardize numeric features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "    \n",
    "    # Combine scaled features with label\n",
    "    processed_df = X_scaled_df.copy()\n",
    "    processed_df['label'] = y.values\n",
    "    \n",
    "    # Add full_text column if it exists in original df\n",
    "    if 'full_text' in df.columns:\n",
    "        processed_df['full_text'] = df['full_text']\n",
    "    \n",
    "    # Simpan label_map sebagai atribut pada dataframe\n",
    "    processed_df.label_map = label_map\n",
    "    \n",
    "    return processed_df, scaler, label_map\n",
    "\n",
    "# 3. Split data\n",
    "def split_data(df, test_size=0.2, val_size=0.1):\n",
    "    # If dataset is very small, use stratification only when possible\n",
    "    if len(df) > 10 and len(df['label'].unique()) > 1:\n",
    "        train_df, test_df = train_test_split(df, test_size=test_size, stratify=df['label'], random_state=42)\n",
    "        train_df, val_df = train_test_split(train_df, test_size=val_size/(1-test_size), stratify=train_df['label'], random_state=42)\n",
    "    else:\n",
    "        train_df, test_df = train_test_split(df, test_size=test_size, random_state=42)\n",
    "        train_df, val_df = train_test_split(train_df, test_size=val_size/(1-test_size), random_state=42)\n",
    "    \n",
    "    return train_df, val_df, test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Custom model combining IndobERT with numeric features\n",
    "class IndobertWithNumericFeatures(nn.Module):\n",
    "    def __init__(self, bert_model_name=\"indobenchmark/indobert-base-p1\", num_features=100, num_labels=2):\n",
    "        super().__init__()\n",
    "        self.bert = AutoModelForSequenceClassification.from_pretrained(bert_model_name, num_labels=num_labels)\n",
    "        self.num_labels = num_labels\n",
    "        \n",
    "        # Layer for numeric features\n",
    "        self.numeric_projection = nn.Sequential(\n",
    "            nn.Linear(num_features, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, 128)\n",
    "        )\n",
    "        \n",
    "        # Layer to combine BERT output with numeric features\n",
    "        self.classifier = nn.Linear(768 + 128, num_labels)\n",
    "        \n",
    "    def forward(self, input_ids=None, attention_mask=None, numeric_features=None, labels=None):\n",
    "        # Process text with BERT\n",
    "        bert_outputs = self.bert.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = bert_outputs.pooler_output\n",
    "        \n",
    "        # Process numeric features\n",
    "        numeric_output = self.numeric_projection(numeric_features)\n",
    "        \n",
    "        # Combine BERT output with numeric features\n",
    "        combined_output = torch.cat([pooled_output, numeric_output], dim=1)\n",
    "        \n",
    "        # Classifier\n",
    "        logits = self.classifier(combined_output)\n",
    "        \n",
    "        # Calculate loss if labels are provided\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "        \n",
    "        return {\"loss\": loss, \"logits\": logits} if loss is not None else {\"logits\": logits}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Custom Dataset for combining numeric features with text\n",
    "class TextWithNumericFeaturesDataset(TorchDataset):\n",
    "    def __init__(self, df, tokenizer, text_column=\"full_text\", max_length=128):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.text_column = text_column\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        # Get all feature columns\n",
    "        self.feature_cols = [col for col in df.columns if col.startswith('feature_')]\n",
    "        \n",
    "        # Separate numeric features and label\n",
    "        self.numeric_features = df[self.feature_cols].values\n",
    "        self.labels = df['label'].values\n",
    "        \n",
    "        # If there's no text column, use placeholder\n",
    "        if text_column not in df.columns:\n",
    "            self.texts = [\"placeholder text\"] * len(df)\n",
    "        else:\n",
    "            self.texts = df[text_column].fillna(\"\").tolist()  # Handle NaN values\n",
    "\n",
    "        print(df.head())\n",
    "        \n",
    "        # Add column_names attribute that Trainer expects\n",
    "        self.column_names = df.columns.tolist()\n",
    "        \n",
    "        # Define features that will be used by the model\n",
    "        self.features = ['input_ids', 'attention_mask', 'numeric_features', 'labels']\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Tokenize text\n",
    "        encoding = self.tokenizer(\n",
    "            self.texts[idx],\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        # Flatten tensor for input_ids and attention_mask\n",
    "        input_ids = encoding['input_ids'].flatten()\n",
    "        attention_mask = encoding['attention_mask'].flatten()\n",
    "        \n",
    "        # Get numeric features and label\n",
    "        numeric_features = torch.tensor(self.numeric_features[idx], dtype=torch.float)\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        \n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'numeric_features': numeric_features,\n",
    "            'labels': label\n",
    "        }\n",
    "    \n",
    "    # Add this method to handle the removal of unused columns\n",
    "    def remove_columns(self, column_names):\n",
    "        # This is a no-op since we're not actually removing columns\n",
    "        # We just need this method to satisfy the Trainer's interface\n",
    "        return self\n",
    "\n",
    "# 6. Custom Trainer for our model\n",
    "class CustomTrainer(Trainer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "    \n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        outputs = model(\n",
    "            input_ids=inputs['input_ids'], \n",
    "            attention_mask=inputs['attention_mask'], \n",
    "            numeric_features=inputs['numeric_features'],\n",
    "            labels=inputs['labels']\n",
    "        )\n",
    "        \n",
    "        loss = outputs['loss']\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "    \n",
    "    # Override _remove_unused_columns to work with our custom dataset\n",
    "    def _remove_unused_columns(self, dataset, description=None):\n",
    "        if not isinstance(dataset, TextWithNumericFeaturesDataset):\n",
    "            return super()._remove_unused_columns(dataset, description)\n",
    "        \n",
    "        # For our custom dataset, just return it as is\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enhanced Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Enhanced metrics calculation with multi-class support\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    probs = torch.nn.functional.softmax(torch.tensor(pred.predictions), dim=-1).numpy()\n",
    "    \n",
    "    # Basic metrics\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    \n",
    "    # Get precision, recall, f1 for each class and average\n",
    "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(\n",
    "        labels, preds, average='macro'\n",
    "    )\n",
    "    precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(\n",
    "        labels, preds, average='weighted'\n",
    "    )\n",
    "    \n",
    "    # Calculate ROC AUC (adapted for multi-class)\n",
    "    try:\n",
    "        if len(np.unique(labels)) > 2:  # Multi-class\n",
    "            # One-vs-Rest approach for multi-class ROC AUC\n",
    "            roc_auc = roc_auc_score(labels, probs, multi_class='ovr', average='macro')\n",
    "        else:  # Binary\n",
    "            roc_auc = roc_auc_score(labels, probs[:, 1])\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: ROC AUC calculation failed: {e}\")\n",
    "        roc_auc = float('nan')\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision_macro': precision_macro,\n",
    "        'recall_macro': recall_macro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'precision_weighted': precision_weighted,\n",
    "        'recall_weighted': recall_weighted,\n",
    "        'f1_weighted': f1_weighted,\n",
    "        'roc_auc': roc_auc\n",
    "    }\n",
    "\n",
    "# Generate comprehensive evaluation report\n",
    "# Generate comprehensive evaluation report\n",
    "def generate_evaluation_report(model, tokenizer, test_dataset, label_map):\n",
    "    device = next(model.parameters()).device\n",
    "    model.eval()\n",
    "    \n",
    "    # Get predictions for all test samples\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    \n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "            for i in tqdm(range(len(test_dataset)), desc=\"Evaluating\"):\n",
    "                sample = test_dataset[i]\n",
    "                \n",
    "                # Move tensors to device\n",
    "                input_ids = sample['input_ids'].unsqueeze(0).to(device)\n",
    "                attention_mask = sample['attention_mask'].unsqueeze(0).to(device)\n",
    "                numeric_features = sample['numeric_features'].unsqueeze(0).to(device)\n",
    "                \n",
    "                # Get prediction\n",
    "                outputs = model(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    numeric_features=numeric_features\n",
    "                )\n",
    "                \n",
    "                logits = outputs['logits']\n",
    "                probs = torch.softmax(logits, dim=1)\n",
    "                prediction = torch.argmax(probs, dim=1).item()\n",
    "                \n",
    "                all_predictions.append(prediction)\n",
    "                all_labels.append(sample['labels'].item())\n",
    "                all_probs.append(probs.cpu().numpy()[0])\n",
    "        \n",
    "        # Convert lists to arrays\n",
    "        all_predictions = np.array(all_predictions)\n",
    "        all_labels = np.array(all_labels)\n",
    "        all_probs = np.array(all_probs)\n",
    "        \n",
    "        # Compute confusion matrix\n",
    "        cm = confusion_matrix(all_labels, all_predictions)\n",
    "        \n",
    "        # Get classification report\n",
    "        reverse_label_map = {v: k for k, v in label_map.items()}\n",
    "        \n",
    "        # Get actual unique classes from dataset\n",
    "        unique_classes = sorted(np.unique(np.concatenate([all_labels, all_predictions])))\n",
    "        target_names = []\n",
    "        \n",
    "        for i in unique_classes:\n",
    "            if i in reverse_label_map:\n",
    "                target_names.append(reverse_label_map[i])\n",
    "            else:\n",
    "                target_names.append(f\"Class_{i}\")  # Fallback for missing labels\n",
    "                \n",
    "        cr = classification_report(all_labels, all_predictions, target_names=target_names, output_dict=True)\n",
    "        \n",
    "        # Calculate ROC AUC\n",
    "        try:\n",
    "            if len(np.unique(all_labels)) > 2:  # Multi-class\n",
    "                roc_auc = roc_auc_score(all_labels, all_probs, multi_class='ovr', average='macro')\n",
    "                # Calculate class-wise ROC AUC\n",
    "                class_roc_auc = {}\n",
    "                for i in unique_classes:\n",
    "                    class_labels = (all_labels == i).astype(int)\n",
    "                    class_name = reverse_label_map.get(i, f\"Class_{i}\")\n",
    "                    class_roc_auc[class_name] = roc_auc_score(class_labels, all_probs[:, i])\n",
    "            else:  # Binary\n",
    "                roc_auc = roc_auc_score(all_labels, all_probs[:, 1])\n",
    "                class_roc_auc = {}\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: ROC AUC calculation failed: {e}\")\n",
    "            roc_auc = float('nan')\n",
    "            class_roc_auc = {}\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        accuracy = accuracy_score(all_labels, all_predictions)\n",
    "        \n",
    "        return {\n",
    "            'confusion_matrix': cm,\n",
    "            'classification_report': cr,\n",
    "            'roc_auc': roc_auc,\n",
    "            'class_roc_auc': class_roc_auc,\n",
    "            'accuracy': accuracy,\n",
    "            'predictions': all_predictions,\n",
    "            'labels': all_labels,\n",
    "            'probabilities': all_probs\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error generating evaluation report: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        \n",
    "        # Return fallback minimal report\n",
    "        return {\n",
    "            'confusion_matrix': np.array([[0]]),\n",
    "            'classification_report': {\"error\": str(e)},\n",
    "            'roc_auc': float('nan'),\n",
    "            'class_roc_auc': {},\n",
    "            'accuracy': 0.0,\n",
    "            'error': str(e)\n",
    "        }\n",
    "\n",
    "# Function to visualize confusion matrix\n",
    "def plot_confusion_matrix(cm, target_names, title='Confusion Matrix'):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=target_names, yticklabels=target_names)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune_indobert_with_numeric(train_df, val_df, test_df, num_features, num_labels=2, output_dir=\"./indobert_numeric_model\"):\n",
    "    # Initialize tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"indobenchmark/indobert-base-p1\")\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = TextWithNumericFeaturesDataset(train_df, tokenizer)\n",
    "    val_dataset = TextWithNumericFeaturesDataset(val_df, tokenizer)\n",
    "    test_dataset = TextWithNumericFeaturesDataset(test_df, tokenizer)\n",
    "    \n",
    "    # Initialize model\n",
    "    model = IndobertWithNumericFeatures(num_features=num_features, num_labels=num_labels)\n",
    "    \n",
    "    # Training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        num_train_epochs=5,\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=8,\n",
    "        warmup_steps=100,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir=os.path.join(output_dir, 'logs'),\n",
    "        logging_steps=10,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"accuracy\",\n",
    "        save_total_limit=2,\n",
    "        fp16=torch.cuda.is_available()  # Use mixed precision if GPU available\n",
    "    )\n",
    "    \n",
    "    # Initialize trainer\n",
    "    trainer = CustomTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "    \n",
    "    # Fine-tune model\n",
    "    print(\"Starting model training...\")\n",
    "    trainer.train()\n",
    "    \n",
    "    # Simple evaluation using Trainer\n",
    "    print(\"Evaluating model on test set...\")\n",
    "    eval_results = trainer.evaluate(test_dataset)\n",
    "    print(f\"Evaluation results: {eval_results}\")\n",
    "    \n",
    "    # Generating a comprehensive evaluation report\n",
    "    print(\"Generating comprehensive evaluation report...\")\n",
    "    \n",
    "    # Fix: Gunakan label_map yang sudah dibuat pada preprocessing\n",
    "    # Ini akan mencegah error saat mencoba membuat label_map baru\n",
    "    if hasattr(test_df, 'label_map') and test_df.label_map is not None:\n",
    "        label_map = test_df.label_map\n",
    "    else:\n",
    "        # Fallback jika tidak ada label_map di test_df\n",
    "        # Kita ambil label yang unik dari dataset test\n",
    "        unique_labels = sorted(test_df['label'].unique())\n",
    "        label_map = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "        \n",
    "    evaluation_report = generate_evaluation_report(model, tokenizer, test_dataset, label_map)\n",
    "    \n",
    "    # Save model and tokenizer\n",
    "    print(f\"Saving model to {output_dir}\")\n",
    "    trainer.save_model(output_dir)\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "    \n",
    "    # Return everything for further analysis\n",
    "    return model, tokenizer, eval_results, evaluation_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Function to predict with the fine-tuned model\n",
    "# 9. Function to predict with the fine-tuned model\n",
    "def predict(model, tokenizer, scaler, features, text=\"\", label_map=None):\n",
    "    try:\n",
    "        # Check if feature count matches what the scaler expects\n",
    "        if len(features) != scaler.n_features_in_:\n",
    "            raise ValueError(f\"Expected {scaler.n_features_in_} features, but got {len(features)}\")\n",
    "        \n",
    "        # Standardize numeric features\n",
    "        scaled_features = scaler.transform([features])[0]\n",
    "        scaled_features_tensor = torch.tensor(scaled_features, dtype=torch.float).unsqueeze(0)\n",
    "        \n",
    "        # Tokenize text\n",
    "        encoding = tokenizer(\n",
    "            text if text else \"placeholder text\",\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=128,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        # Move tensors to the same device as model\n",
    "        device = next(model.parameters()).device\n",
    "        input_ids = encoding['input_ids'].to(device)\n",
    "        attention_mask = encoding['attention_mask'].to(device)\n",
    "        scaled_features_tensor = scaled_features_tensor.to(device)\n",
    "        \n",
    "        # Prediction\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = model(\n",
    "                input_ids=input_ids, \n",
    "                attention_mask=attention_mask, \n",
    "                numeric_features=scaled_features_tensor\n",
    "            )\n",
    "        \n",
    "        # Get logits and convert to probabilities\n",
    "        logits = outputs['logits']\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        \n",
    "        # Get class with highest probability\n",
    "        predicted_class = torch.argmax(probs, dim=1).item()\n",
    "        \n",
    "        # Determine predicted label\n",
    "        if label_map:\n",
    "            reverse_label_map = {v: k for k, v in label_map.items()}\n",
    "            predicted_label = reverse_label_map.get(predicted_class, f\"Unknown class {predicted_class}\")\n",
    "        else:\n",
    "            # Try to infer based on model's output size\n",
    "            num_classes = probs.shape[1]\n",
    "            if num_classes == 2:\n",
    "                default_map = {0: 'negatif', 1: 'positif'}\n",
    "            elif num_classes == 3:\n",
    "                default_map = {0: 'negatif', 1: 'positif', 2: 'netral'}\n",
    "            else:\n",
    "                default_map = {i: f\"Class_{i}\" for i in range(num_classes)}\n",
    "            \n",
    "            predicted_label = default_map.get(predicted_class, f\"Class_{predicted_class}\")\n",
    "        \n",
    "        return {\n",
    "            'predicted_class': predicted_class,\n",
    "            'predicted_label': predicted_label,\n",
    "            'confidence': probs[0][predicted_class].item(),\n",
    "            'all_probabilities': {i: p.item() for i, p in enumerate(probs[0])}\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in prediction: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return {\n",
    "            'error': str(e),\n",
    "            'predicted_label': None,\n",
    "            'confidence': 0.0,\n",
    "            'all_probabilities': {}\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Execution Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Main function for fine-tuning and testing with enhanced evaluation\n",
    "def main(file_path, output_dir=\"./indobert_numeric_model\"):\n",
    "    # Load dataset\n",
    "    print(f\"Loading dataset from {file_path}\")\n",
    "    df = load_dataset(file_path)\n",
    "    \n",
    "    # Make sure dataset has label column\n",
    "    if 'label' not in df.columns:\n",
    "        raise ValueError(\"Dataset must have a 'label' column\")\n",
    "    \n",
    "    # Check feature columns\n",
    "    feature_cols = [col for col in df.columns if col.startswith('feature_')]\n",
    "    if len(feature_cols) == 0:\n",
    "        raise ValueError(\"No feature columns found. Feature columns should start with 'feature_'\")\n",
    "    \n",
    "    # Check if text column exists\n",
    "    if 'full_text' not in df.columns:\n",
    "        print(\"Warning: 'full_text' column not found. Adding placeholder text.\")\n",
    "        df['full_text'] = \"placeholder text\"\n",
    "    \n",
    "    # Check dataset size\n",
    "    print(f\"Dataset shape: {df.shape}\")\n",
    "    \n",
    "    # Preprocess data\n",
    "    print(\"Preprocessing dataset...\")\n",
    "    processed_df, scaler, label_map = preprocess_data(df)\n",
    "    \n",
    "    # Count labels\n",
    "    label_counts = processed_df['label'].value_counts()\n",
    "    print(f\"Label distribution: {label_counts}\")\n",
    "    \n",
    "    # Split data\n",
    "    print(\"Splitting dataset into train, validation, and test sets...\")\n",
    "    train_df, val_df, test_df = split_data(processed_df)\n",
    "    print(f\"Train set size: {len(train_df)}, Val set size: {len(val_df)}, Test set size: {len(test_df)}\")\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Save preprocessed data and artifacts\n",
    "    print(f\"Saving preprocessed data and artifacts to {output_dir}\")\n",
    "    processed_df.to_csv(os.path.join(output_dir, 'processed_data.csv'), index=False)\n",
    "    joblib.dump(scaler, os.path.join(output_dir, 'scaler.pkl'))\n",
    "    joblib.dump(label_map, os.path.join(output_dir, 'label_map.pkl'))\n",
    "    \n",
    "    # Fine-tune model\n",
    "    num_features = len(feature_cols)\n",
    "    num_labels = len(label_map)\n",
    "    print(f\"Starting fine-tuning with {num_features} features and {num_labels} labels...\")\n",
    "    \n",
    "    try:\n",
    "        model, tokenizer, eval_results, evaluation_report = fine_tune_indobert_with_numeric(\n",
    "            train_df, val_df, test_df, \n",
    "            num_features=num_features, \n",
    "            num_labels=num_labels, \n",
    "            output_dir=output_dir\n",
    "        )\n",
    "        \n",
    "        # Save evaluation results\n",
    "        print(f\"Saving evaluation results to {output_dir}\")\n",
    "        with open(os.path.join(output_dir, 'eval_results.txt'), 'w') as f:\n",
    "            f.write(str(eval_results))\n",
    "        \n",
    "        # Generate and save detailed evaluation metrics\n",
    "        # Get actual class names from the classification report\n",
    "        cr = evaluation_report['classification_report']\n",
    "        class_metrics_keys = [k for k in cr.keys() if k not in ['accuracy', 'macro avg', 'weighted avg']]\n",
    "        \n",
    "        # Save confusion matrix\n",
    "        cm_plot = plot_confusion_matrix(\n",
    "            evaluation_report['confusion_matrix'], \n",
    "            class_metrics_keys, \n",
    "            title='Confusion Matrix'\n",
    "        )\n",
    "        cm_plot.savefig(os.path.join(output_dir, 'confusion_matrix.png'))\n",
    "        plt.close()\n",
    "        \n",
    "        # Visualize class-wise metrics\n",
    "        try:\n",
    "            class_metrics = pd.DataFrame({\n",
    "                'precision': [cr[label]['precision'] for label in class_metrics_keys],\n",
    "                'recall': [cr[label]['recall'] for label in class_metrics_keys],\n",
    "                'f1-score': [cr[label]['f1-score'] for label in class_metrics_keys],\n",
    "                'support': [cr[label]['support'] for label in class_metrics_keys]\n",
    "            }, index=class_metrics_keys)\n",
    "            \n",
    "            plt.figure(figsize=(10, 6))\n",
    "            class_metrics[['precision', 'recall', 'f1-score']].plot(kind='bar')\n",
    "            plt.title('Class-wise Metrics')\n",
    "            plt.ylabel('Score')\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(output_dir, 'class_metrics.png'))\n",
    "            plt.close()\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Error generating class metrics visualization: {e}\")\n",
    "            print(\"Classification report keys:\", list(cr.keys()))\n",
    "        \n",
    "        # Save full evaluation report as JSON\n",
    "        import json\n",
    "        with open(os.path.join(output_dir, 'full_evaluation.json'), 'w') as f:\n",
    "            # Convert numpy arrays and other non-serializable objects to standard types\n",
    "            try:\n",
    "                serializable_report = {\n",
    "                    'confusion_matrix': evaluation_report['confusion_matrix'].tolist(),\n",
    "                    'classification_report': evaluation_report['classification_report'],\n",
    "                    'roc_auc': float(evaluation_report['roc_auc']) if not np.isnan(evaluation_report['roc_auc']) else \"NaN\",\n",
    "                    'class_roc_auc': {k: float(v) if not np.isnan(v) else \"NaN\" for k, v in evaluation_report['class_roc_auc'].items()},\n",
    "                    'accuracy': float(evaluation_report['accuracy'])\n",
    "                }\n",
    "                json.dump(serializable_report, f, indent=2)\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Error serializing evaluation report: {e}\")\n",
    "                # Fallback to a simpler report\n",
    "                json.dump({\n",
    "                    'accuracy': float(evaluation_report['accuracy']),\n",
    "                    'error_serializing_full_report': str(e)\n",
    "                }, f, indent=2)\n",
    "        \n",
    "        # Create a sample prediction\n",
    "        if len(test_df) > 0:\n",
    "            try:\n",
    "                print(\"Generating a sample prediction...\")\n",
    "                sample = test_df.iloc[0]\n",
    "                features = sample[[col for col in sample.index if col.startswith('feature_')]].values\n",
    "                text = sample.get('full_text', '')\n",
    "                \n",
    "                prediction = predict(model, tokenizer, scaler, features, text, label_map)\n",
    "                print(f\"Sample prediction: {prediction}\")\n",
    "                \n",
    "                # Get actual label using the label_map\n",
    "                reverse_label_map = {v: k for k, v in label_map.items()}\n",
    "                actual_label = reverse_label_map.get(sample['label'], f\"Unknown label {sample['label']}\")\n",
    "                print(f\"Actual label: {actual_label}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Error generating sample prediction: {e}\")\n",
    "    \n",
    "        print(f\"Model training and evaluation complete. Results saved to {output_dir}\")\n",
    "        return model, tokenizer, scaler, label_map, evaluation_report\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error during model training and evaluation: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from ./preprocess_data/word2vec_vectors(withlabel).csv\n",
      "Dataset shape: (2053, 102)\n",
      "Preprocessing dataset...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2053 entries, 0 to 2052\n",
      "Data columns (total 100 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   feature_0   2053 non-null   float64\n",
      " 1   feature_1   2053 non-null   float64\n",
      " 2   feature_2   2053 non-null   float64\n",
      " 3   feature_3   2053 non-null   float64\n",
      " 4   feature_4   2053 non-null   float64\n",
      " 5   feature_5   2053 non-null   float64\n",
      " 6   feature_6   2053 non-null   float64\n",
      " 7   feature_7   2053 non-null   float64\n",
      " 8   feature_8   2053 non-null   float64\n",
      " 9   feature_9   2053 non-null   float64\n",
      " 10  feature_10  2053 non-null   float64\n",
      " 11  feature_11  2053 non-null   float64\n",
      " 12  feature_12  2053 non-null   float64\n",
      " 13  feature_13  2053 non-null   float64\n",
      " 14  feature_14  2053 non-null   float64\n",
      " 15  feature_15  2053 non-null   float64\n",
      " 16  feature_16  2053 non-null   float64\n",
      " 17  feature_17  2053 non-null   float64\n",
      " 18  feature_18  2053 non-null   float64\n",
      " 19  feature_19  2053 non-null   float64\n",
      " 20  feature_20  2053 non-null   float64\n",
      " 21  feature_21  2053 non-null   float64\n",
      " 22  feature_22  2053 non-null   float64\n",
      " 23  feature_23  2053 non-null   float64\n",
      " 24  feature_24  2053 non-null   float64\n",
      " 25  feature_25  2053 non-null   float64\n",
      " 26  feature_26  2053 non-null   float64\n",
      " 27  feature_27  2053 non-null   float64\n",
      " 28  feature_28  2053 non-null   float64\n",
      " 29  feature_29  2053 non-null   float64\n",
      " 30  feature_30  2053 non-null   float64\n",
      " 31  feature_31  2053 non-null   float64\n",
      " 32  feature_32  2053 non-null   float64\n",
      " 33  feature_33  2053 non-null   float64\n",
      " 34  feature_34  2053 non-null   float64\n",
      " 35  feature_35  2053 non-null   float64\n",
      " 36  feature_36  2053 non-null   float64\n",
      " 37  feature_37  2053 non-null   float64\n",
      " 38  feature_38  2053 non-null   float64\n",
      " 39  feature_39  2053 non-null   float64\n",
      " 40  feature_40  2053 non-null   float64\n",
      " 41  feature_41  2053 non-null   float64\n",
      " 42  feature_42  2053 non-null   float64\n",
      " 43  feature_43  2053 non-null   float64\n",
      " 44  feature_44  2053 non-null   float64\n",
      " 45  feature_45  2053 non-null   float64\n",
      " 46  feature_46  2053 non-null   float64\n",
      " 47  feature_47  2053 non-null   float64\n",
      " 48  feature_48  2053 non-null   float64\n",
      " 49  feature_49  2053 non-null   float64\n",
      " 50  feature_50  2053 non-null   float64\n",
      " 51  feature_51  2053 non-null   float64\n",
      " 52  feature_52  2053 non-null   float64\n",
      " 53  feature_53  2053 non-null   float64\n",
      " 54  feature_54  2053 non-null   float64\n",
      " 55  feature_55  2053 non-null   float64\n",
      " 56  feature_56  2053 non-null   float64\n",
      " 57  feature_57  2053 non-null   float64\n",
      " 58  feature_58  2053 non-null   float64\n",
      " 59  feature_59  2053 non-null   float64\n",
      " 60  feature_60  2053 non-null   float64\n",
      " 61  feature_61  2053 non-null   float64\n",
      " 62  feature_62  2053 non-null   float64\n",
      " 63  feature_63  2053 non-null   float64\n",
      " 64  feature_64  2053 non-null   float64\n",
      " 65  feature_65  2053 non-null   float64\n",
      " 66  feature_66  2053 non-null   float64\n",
      " 67  feature_67  2053 non-null   float64\n",
      " 68  feature_68  2053 non-null   float64\n",
      " 69  feature_69  2053 non-null   float64\n",
      " 70  feature_70  2053 non-null   float64\n",
      " 71  feature_71  2053 non-null   float64\n",
      " 72  feature_72  2053 non-null   float64\n",
      " 73  feature_73  2053 non-null   float64\n",
      " 74  feature_74  2053 non-null   float64\n",
      " 75  feature_75  2053 non-null   float64\n",
      " 76  feature_76  2053 non-null   float64\n",
      " 77  feature_77  2053 non-null   float64\n",
      " 78  feature_78  2053 non-null   float64\n",
      " 79  feature_79  2053 non-null   float64\n",
      " 80  feature_80  2053 non-null   float64\n",
      " 81  feature_81  2053 non-null   float64\n",
      " 82  feature_82  2053 non-null   float64\n",
      " 83  feature_83  2053 non-null   float64\n",
      " 84  feature_84  2053 non-null   float64\n",
      " 85  feature_85  2053 non-null   float64\n",
      " 86  feature_86  2053 non-null   float64\n",
      " 87  feature_87  2053 non-null   float64\n",
      " 88  feature_88  2053 non-null   float64\n",
      " 89  feature_89  2053 non-null   float64\n",
      " 90  feature_90  2053 non-null   float64\n",
      " 91  feature_91  2053 non-null   float64\n",
      " 92  feature_92  2053 non-null   float64\n",
      " 93  feature_93  2053 non-null   float64\n",
      " 94  feature_94  2053 non-null   float64\n",
      " 95  feature_95  2053 non-null   float64\n",
      " 96  feature_96  2053 non-null   float64\n",
      " 97  feature_97  2053 non-null   float64\n",
      " 98  feature_98  2053 non-null   float64\n",
      " 99  feature_99  2053 non-null   float64\n",
      "dtypes: float64(100)\n",
      "memory usage: 1.6 MB\n",
      "None\n",
      "Label distribution: label\n",
      "2    955\n",
      "0    661\n",
      "1    437\n",
      "Name: count, dtype: int64\n",
      "Splitting dataset into train, validation, and test sets...\n",
      "Train set size: 1436, Val set size: 206, Test set size: 411\n",
      "Saving preprocessed data and artifacts to ./indobert_numeric_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_279064/4139800313.py:41: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  processed_df.label_map = label_map\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fine-tuning with 100 features and 3 labels...\n",
      "      feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
      "1286  -1.589342   1.750251  -1.303826   0.690223  -1.281000   0.196706   \n",
      "767    0.318047  -0.857611  -0.269556   0.573528   2.189672  -0.907528   \n",
      "949   -1.622044   0.519182  -0.022012  -0.665681  -0.324416   0.152355   \n",
      "1145   0.592219  -1.256644   0.981063  -1.214813  -0.177711  -1.146956   \n",
      "2039   0.996703   0.405190  -0.624630   0.803030  -1.136049  -0.352076   \n",
      "\n",
      "      feature_6  feature_7  feature_8  feature_9  ...  feature_92  feature_93  \\\n",
      "1286   0.105051   0.320559  -0.121987   1.797113  ...   -1.481076   -0.485232   \n",
      "767    1.298382   0.523074  -0.028533  -1.018742  ...    3.013536    0.469018   \n",
      "949   -0.323390   0.772670   1.544980  -0.472867  ...    0.711473    1.297700   \n",
      "1145  -0.950345   0.617145  -0.031929  -1.397556  ...    0.263638    0.266970   \n",
      "2039  -0.686280  -1.346339  -0.958856   0.225244  ...   -1.592414   -1.129746   \n",
      "\n",
      "      feature_94  feature_95  feature_96  feature_97  feature_98  feature_99  \\\n",
      "1286   -0.494109   -0.372165    0.897913   -0.312444   -0.286861   -0.354617   \n",
      "767     1.668645    1.427632    2.168973   -0.043177   -0.978151   -0.715044   \n",
      "949     0.607470   -0.811259   -1.011454    1.639322    0.826656   -0.700088   \n",
      "1145    0.012145    0.262721   -0.964887   -0.131431    0.938474    0.318215   \n",
      "2039   -0.659785   -0.044722   -0.140255   -2.016275   -1.189330    1.341647   \n",
      "\n",
      "      label                                          full_text  \n",
      "1286      1  direktorat jenderal pendidikan vokasi menerbit...  \n",
      "767       1  universitas bsi dukung rakornas aptikom 2021 k...  \n",
      "949       1  obe bukan hanya tentang kurikulum tapi perubah...  \n",
      "1145      0  pusing sekali jadi mahasiswa jaman sekarang ti...  \n",
      "2039      2  anakanak lebih semangat presentasi hasil proje...  \n",
      "\n",
      "[5 rows x 102 columns]\n",
      "      feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
      "2048  -1.373298   1.284894  -1.260338   0.961018   0.478428   1.513214   \n",
      "605   -0.131038  -0.417654   1.084873  -1.851469  -0.265406  -1.136201   \n",
      "1614   0.277412  -0.356771   1.180054  -0.813106   1.958683   1.596965   \n",
      "413   -0.528737  -0.068487  -1.588229   1.135236   1.864332  -0.402209   \n",
      "587   -0.381517  -0.276999   0.084033   0.506640   0.146185  -1.245994   \n",
      "\n",
      "      feature_6  feature_7  feature_8  feature_9  ...  feature_92  feature_93  \\\n",
      "2048   0.279283  -1.355820  -0.005359   1.091082  ...    0.065724   -0.709165   \n",
      "605   -1.585487   1.383249   0.921783  -1.394212  ...   -0.031322    0.963287   \n",
      "1614   1.717696  -0.356127  -0.253000   0.958521  ...    0.745342    0.683529   \n",
      "413    1.109602  -0.071218  -0.453719   0.360437  ...    2.155157   -0.285615   \n",
      "587    0.646040  -0.060857  -0.287711  -0.588535  ...    0.461753   -0.761850   \n",
      "\n",
      "      feature_94  feature_95  feature_96  feature_97  feature_98  feature_99  \\\n",
      "2048   -0.035242   -1.298063    0.045672    0.024224   -0.324770    1.701711   \n",
      "605     0.484594    0.446180   -0.812184    0.134539    0.832606   -1.405084   \n",
      "1614   -1.014048    0.023949    0.168766    0.716929    1.854970   -1.522324   \n",
      "413     1.425156    0.784864    2.796306   -0.447817   -1.295721   -0.318078   \n",
      "587     0.229840    0.905280    1.061932   -1.020649   -0.440720    0.645326   \n",
      "\n",
      "      label                                          full_text  \n",
      "2048      2  metode obe membantu siswa memahami materi deng...  \n",
      "605       2  pastikan lulusan berkompetensi unggul politekn...  \n",
      "1614      0  pendidikan berbasis hasil harusnya jadi solusi...  \n",
      "413       1  departemen ilmu komputer pg orientasi terorgan...  \n",
      "587       0  moegovsa kauweb admissionweb assalamualaikumpa...  \n",
      "\n",
      "[5 rows x 102 columns]\n",
      "      feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
      "800   -0.722379   0.511696  -0.357218   0.028196  -0.350568   0.312526   \n",
      "111   -3.594022   3.223619  -3.174309   1.771387  -3.271250  -0.153746   \n",
      "798    0.043509  -0.455561   0.187889  -0.228267   0.239851  -0.860782   \n",
      "361   -1.318847   1.323260  -1.410471   1.358348  -0.356123   0.137351   \n",
      "1896   0.305141   1.433769  -1.989905   1.079685  -1.966553  -0.567815   \n",
      "\n",
      "      feature_6  feature_7  feature_8  feature_9  ...  feature_92  feature_93  \\\n",
      "800   -0.209985   0.231833   0.675575  -0.026014  ...    0.233393    0.593526   \n",
      "111   -2.800808  -1.302854   2.420618  -0.024959  ...   -1.265379   -0.038048   \n",
      "798   -1.061613   0.418339   0.658984  -1.428111  ...    0.795355    0.225529   \n",
      "361    0.947722  -1.006173   0.122448   0.714317  ...    0.049563   -0.359565   \n",
      "1896  -2.583789  -1.407993   1.139364  -1.125119  ...   -0.108944    0.541441   \n",
      "\n",
      "      feature_94  feature_95  feature_96  feature_97  feature_98  feature_99  \\\n",
      "800     0.026405   -0.777750   -0.529666    0.970580    0.119592    0.018769   \n",
      "111     0.735517   -2.924402   -1.982678   -0.072486   -2.296183    3.111266   \n",
      "798     1.275966    0.300026   -0.059404    0.109658   -0.578262    0.563277   \n",
      "361    -0.370975   -0.741455    0.258335   -0.734123   -0.864041    0.673951   \n",
      "1896    1.050031   -1.201823   -0.636576   -0.693384   -2.629731    2.144827   \n",
      "\n",
      "      label                                          full_text  \n",
      "800       0  banyak yang tidak ngeh tetapi ini contoh dari ...  \n",
      "111       0            joeymannarinous outcome based education  \n",
      "798       1  halo temanmamin jurusan manajemen s1 menyeleng...  \n",
      "361       1  vikas maniar associate professor cete dan angg...  \n",
      "1896      2              anakanak suka sama projectproject obe  \n",
      "\n",
      "[5 rows x 102 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/whoami/.local/lib/python3.12/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='900' max='900' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [900/900 1:00:31, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision Macro</th>\n",
       "      <th>Recall Macro</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>Precision Weighted</th>\n",
       "      <th>Recall Weighted</th>\n",
       "      <th>F1 Weighted</th>\n",
       "      <th>Roc Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.604800</td>\n",
       "      <td>0.520026</td>\n",
       "      <td>0.810680</td>\n",
       "      <td>0.790396</td>\n",
       "      <td>0.773990</td>\n",
       "      <td>0.778923</td>\n",
       "      <td>0.805748</td>\n",
       "      <td>0.810680</td>\n",
       "      <td>0.805908</td>\n",
       "      <td>0.911721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.553100</td>\n",
       "      <td>0.606237</td>\n",
       "      <td>0.796117</td>\n",
       "      <td>0.783868</td>\n",
       "      <td>0.810290</td>\n",
       "      <td>0.787584</td>\n",
       "      <td>0.820563</td>\n",
       "      <td>0.796117</td>\n",
       "      <td>0.798323</td>\n",
       "      <td>0.912502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.222800</td>\n",
       "      <td>0.789648</td>\n",
       "      <td>0.781553</td>\n",
       "      <td>0.764047</td>\n",
       "      <td>0.766730</td>\n",
       "      <td>0.763019</td>\n",
       "      <td>0.791812</td>\n",
       "      <td>0.781553</td>\n",
       "      <td>0.784885</td>\n",
       "      <td>0.910958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.147700</td>\n",
       "      <td>1.066725</td>\n",
       "      <td>0.776699</td>\n",
       "      <td>0.759943</td>\n",
       "      <td>0.755997</td>\n",
       "      <td>0.756342</td>\n",
       "      <td>0.781644</td>\n",
       "      <td>0.776699</td>\n",
       "      <td>0.777689</td>\n",
       "      <td>0.912412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.087300</td>\n",
       "      <td>1.191170</td>\n",
       "      <td>0.771845</td>\n",
       "      <td>0.756929</td>\n",
       "      <td>0.748422</td>\n",
       "      <td>0.750764</td>\n",
       "      <td>0.777287</td>\n",
       "      <td>0.771845</td>\n",
       "      <td>0.772693</td>\n",
       "      <td>0.909484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model on test set...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='52' max='52' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [52/52 00:44]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results: {'eval_loss': 0.6822099089622498, 'eval_accuracy': 0.7469586374695864, 'eval_precision_macro': 0.7156040433925049, 'eval_recall_macro': 0.6973861653181025, 'eval_f1_macro': 0.6899248272922659, 'eval_precision_weighted': 0.735262654947523, 'eval_recall_weighted': 0.7469586374695864, 'eval_f1_weighted': 0.7290905471591692, 'eval_roc_auc': 0.8591470370591435, 'eval_runtime': 45.8425, 'eval_samples_per_second': 8.965, 'eval_steps_per_second': 1.134, 'epoch': 5.0}\n",
      "Generating comprehensive evaluation report...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ac7aa846c1b4de88b8e886a62b7107b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/411 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to ./indobert_numeric_model\n",
      "Saving evaluation results to ./indobert_numeric_model\n",
      "Warning: Error serializing evaluation report: keys must be str, int, float, bool or None, not int64\n",
      "Generating a sample prediction...\n",
      "Sample prediction: {'predicted_class': 0, 'predicted_label': 'negatif', 'confidence': 0.7219417095184326, 'all_probabilities': {0: 0.7219417095184326, 1: 0.1484224945306778, 2: 0.12963585555553436}}\n",
      "Actual label: negatif\n",
      "Model training and evaluation complete. Results saved to ./indobert_numeric_model\n",
      "Training dan evaluasi selesai!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/whoami/.local/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_path = \"./preprocess_data/word2vec_vectors(withlabel).csv\"  # Ganti dengan path file CSV Anda\n",
    "output_dir = \"./indobert_numeric_model\"  # Direktori untuk menyimpan model dan hasil evaluasi\n",
    "\n",
    "model, tokenizer, scaler, label_map, evaluation_report = main(file_path, output_dir)\n",
    "print(\"Training dan evaluasi selesai!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_evaluation_results(evaluation_report, label_map):\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"HASIL EVALUASI MODEL\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Reverse label map untuk menampilkan nama label\n",
    "    reverse_label_map = {v: k for k, v in label_map.items()}\n",
    "    target_names = [reverse_label_map[i] for i in range(len(label_map))]\n",
    "    \n",
    "    # Tampilkan accuracy\n",
    "    print(f\"\\nAkurasi: {evaluation_report['accuracy']:.4f}\")\n",
    "    \n",
    "    # Tampilkan ROC AUC\n",
    "    print(f\"ROC AUC: {evaluation_report['roc_auc']:.4f}\")\n",
    "    \n",
    "    # Tampilkan confusion matrix\n",
    "    # Visualisasi confusion matrix \n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    cm = evaluation_report['confusion_matrix']\n",
    "    \n",
    "    # Buat plot visualisasi\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # Hitung persentase normalisasi (opsional untuk tampilan tambahan)\n",
    "    cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "    \n",
    "    # Plot heatmap dengan annotasi nilai dalam matrix\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=target_names, yticklabels=target_names)\n",
    "    \n",
    "    # Tambahkan judul dan label\n",
    "    plt.title('Confusion Matrix', fontsize=16)\n",
    "    plt.xlabel('Predicted Label', fontsize=12)\n",
    "    plt.ylabel('True Label', fontsize=12)\n",
    "    \n",
    "    # Rotasi label untuk keterbacaan yang lebih baik jika nama label panjang\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    \n",
    "    # Tampilkan plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Tampilkan classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    cr = evaluation_report['classification_report']\n",
    "    \n",
    "    headers = [\"precision\", \"recall\", \"f1-score\", \"support\"]\n",
    "    rows = []\n",
    "    \n",
    "    # Tambahkan hasil untuk setiap kelas\n",
    "    for i, label in enumerate(target_names):\n",
    "        # Gunakan indeks numerik untuk mengakses classification report\n",
    "        if str(i) in cr:  # Gunakan str karena kunci mungkin disimpan sebagai string\n",
    "            class_data = cr[str(i)]\n",
    "        elif i in cr:  # Atau coba langsung dengan indeks numerik\n",
    "            class_data = cr[i]\n",
    "        else:\n",
    "            # Jika tidak ditemukan, gunakan label sebagai kunci\n",
    "            class_data = cr.get(label, {'precision': 0, 'recall': 0, 'f1-score': 0, 'support': 0})\n",
    "        \n",
    "        row = [\n",
    "            f\"{class_data['precision']:.4f}\",\n",
    "            f\"{class_data['recall']:.4f}\",\n",
    "            f\"{class_data['f1-score']:.4f}\",\n",
    "            f\"{class_data['support']}\"\n",
    "        ]\n",
    "        rows.append([label] + row)\n",
    "    \n",
    "    # Tambahkan baris untuk accuracy, macro avg, dan weighted avg\n",
    "    for avg_type in ['accuracy', 'macro avg', 'weighted avg']:\n",
    "        if avg_type in cr:\n",
    "            values = cr[avg_type]\n",
    "            if avg_type == 'accuracy':\n",
    "                row = [avg_type, f\"{values:.4f}\", \"\", \"\", f\"{cr['macro avg']['support']}\"]\n",
    "            else:\n",
    "                row = [\n",
    "                    avg_type,\n",
    "                    f\"{values['precision']:.4f}\",\n",
    "                    f\"{values['recall']:.4f}\", \n",
    "                    f\"{values['f1-score']:.4f}\",\n",
    "                    f\"{values['support']}\"\n",
    "                ]\n",
    "            rows.append(row)\n",
    "    \n",
    "    # Tampilkan sebagai tabel\n",
    "    print(pd.DataFrame(rows, columns=[\"\"] + headers).to_string(index=False))\n",
    "    \n",
    "    # Tampilkan ROC AUC untuk setiap kelas\n",
    "    if 'class_roc_auc' in evaluation_report and evaluation_report['class_roc_auc']:\n",
    "        print(\"\\nROC AUC per kelas:\")\n",
    "        class_roc_auc = evaluation_report['class_roc_auc']\n",
    "        \n",
    "        # Cek format dari class_roc_auc dan tampilkan sesuai\n",
    "        if isinstance(class_roc_auc, dict):\n",
    "            # Jika berupa dictionary dengan kunci numerik, konversi ke nama label\n",
    "            for key, auc in class_roc_auc.items():\n",
    "                try:\n",
    "                    # Coba konversi ke int jika kunci berupa string angka\n",
    "                    if isinstance(key, str) and key.isdigit():\n",
    "                        key = int(key)\n",
    "                    \n",
    "                    if key in reverse_label_map:\n",
    "                        label_name = reverse_label_map[key]\n",
    "                    else:\n",
    "                        label_name = key\n",
    "                    print(f\"{label_name}: {auc:.4f}\")\n",
    "                except:\n",
    "                    # Jika gagal, tampilkan apa adanya\n",
    "                    print(f\"{key}: {auc:.4f}\")\n",
    "        else:\n",
    "            # Jika berupa list, tampilkan sesuai urutan kelas\n",
    "            for i, auc in enumerate(class_roc_auc):\n",
    "                label_name = reverse_label_map.get(i, f\"Class {i}\")\n",
    "                print(f\"{label_name}: {auc:.4f}\")\n",
    "    \n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "HASIL EVALUASI MODEL\n",
      "==================================================\n",
      "\n",
      "Akurasi: 0.7470\n",
      "ROC AUC: 0.8591\n",
      "\n",
      "Confusion Matrix:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "             precision recall f1-score support\n",
      "     negatif    0.7456 0.9545   0.8372   132.0\n",
      "      netral    0.6200 0.3523   0.4493    88.0\n",
      "     positif    0.7812 0.7853   0.7833   191.0\n",
      "    accuracy    0.7470                   411.0\n",
      "   macro avg    0.7156 0.6974   0.6899   411.0\n",
      "weighted avg    0.7353 0.7470   0.7291   411.0\n",
      "\n",
      "ROC AUC per kelas:\n",
      "negatif: 0.9228\n",
      "netral: 0.7586\n",
      "positif: 0.8960\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "display_evaluation_results(evaluation_report, label_map)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
